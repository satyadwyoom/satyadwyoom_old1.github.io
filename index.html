<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
/* Stolen from Sergey */
  a {
  color: #1772d0;
  text-decoration:none;
  }
  a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
  }
  body,td,th {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 14px
  }
  strong {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 13px
  }
  heading {
        font-family: 'Lato', Verdana, Helvetica, sans-serif;
        font-size: 15px;
        font-weight: 700
  }
  </style>


  <title>Satyadwyoom Kumar</title>
  
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody><tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tbody><tr>
            <td width="67%" valign="middle">

              <p align="center"><font size="6">Satyadwyoom Kumar</font>

</p><p>I am an Undergraduate student at <a href="http://nsit.ac.in/">Netaji Subhas Institute of Technology</a>. My Research Interests include Reinforcement Learning, Adversarial ML, Computer Vision<br> <br>



              <p style="text-align:center">
                <a href="mailto:satyadwyoom.ec18@nsut.ac.in" target="_blank">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/satya-d-60bb1a169/" target="_blank">Linkedin</a> &nbsp/&nbsp
		<a href="https://github.com/satyadwyoom" target="_blank">GitHub</a>
              </p>

		<!-- <em> <font color="red">There is a poetry in our existence. I want to dance on every rythm and syllable of this poem.</font></em> <br> -->


            </td>

            <td width="25%"><img width="300" src="circle-cropped.png"></td>
          </tr>
        </tbody></table>
		<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        
			<tbody><tr><td>
        <h1>PROJECTS</h1>
<!-- <i>Imagine you want to take your partner down the memory lane and show them the place where you grew up -- the lake, the greenery and the mountains, and make them hear the melodies of chirping birds, the dancing trees, and the rustling leaves. How would the place look like on a sunny day? How mesmerizing it becomes with clouds and rain?  How important mountains and forests were to the beauty of the area? and how gloomy it became when the lake once dried up due to the drought?</i> <em> <font color="red">What if I give you a tool to do that. </font></em> <br><br> -->



		</td></tr>
	</tbody></table>


        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="25%"><img width="400" height="200" src="DRL-gifs/soccer.gif">
            </td><td width="75%" valign="top">
              <p><a href="https://github.com/satyadwyoom/Deep-Reinforcement-Learning/blob/master/soccer-DQN/Soccer.ipynb" target="_blank"><heading>A Multi-Agent DQN based Soccer Playing Agent</heading></a><br>
              <p>Goalies and Strikers were trained from two separate Experience Replays Respectively.<br></p> 

        <br>
            </td>
          </tr>

</tbody>

<tbody><tr>
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <td width="25%"><img width="400" height="200" src="DRL-gifs/Tennis.gif">
            </td><td width="75%" valign="top">
              <p><a href="https://github.com/satyadwyoom/Deep-Reinforcement-Learning/tree/master/TENNIS-TD3" target="_blank"><heading>A Multi-Agent TD3 based Tennis Playing Agent</heading></a><br>
              <p>Both the agents uses their combined experience to improve themselves.<br></p> 

          <br>
            </td>
          </tr>

</tbody>

<tbody><tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <td width="25%"><img width="400" height="200" src="DRL-gifs/Lunarlander.gif">
              </td><td width="75%" valign="top">
                <p><a href="https://github.com/satyadwyoom/CEM-application/tree/master/lunarlander" target="_blank"><heading>Evolutionary algorithm based Lunar Lander</heading></a><br>
                <p>Cross-entropy method was used to make a smart lander which could land on the surface between the two flags.<br></p> 

            <br>
              </td>
            </tr>

</tbody>

<tbody><tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <td width="25%"><img width="400" height="200" src="DRL-gifs/TD3-BipedalWalker.gif">
              </td><td width="75%" valign="top">
                <p><a href="https://github.com/satyadwyoom/Deep-Reinforcement-Learning/tree/master/TD3-BipedalWalker" target="_blank"><heading>A Twin Delayed DDPG based Bipedal Walker</heading></a><br>
                <p>The Bipedal Walker not only learns to stand but also learns to run.<br></p> 

            <br>
              </td>
            </tr>

</tbody>
<tbody><tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <td width="25%"><img width="400" height="200" src="DRL-gifs/banana-DQN.gif">
              </td><td width="75%" valign="top">
                <p><a href="https://github.com/satyadwyoom/Deep-Reinforcement-Learning/tree/master/DQN%20-%20Banana" target="_blank"><heading>A DQN based Banana Navigator and Collector Playing Agent</heading></a><br>
                <p>The agent Navigates through a region containing yellow and blue bananas lying in close proximity to each-other and collects only yellow bananas.<br></p> 

            <br>
              </td>
            </tr>

</tbody>

<tbody><tr>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <td width="25%"><img width="400" height="200" src="DRL-gifs/Reacher.gif">
    </td><td width="75%" valign="top">
      <p><a href="https://github.com/satyadwyoom/Deep-Reinforcement-Learning/tree/master/continuous-control" target="_blank"><heading>A DDPG based Reacher Agent</heading></a><br>
      <p>The agent tries to maintain the tip of the arm inside the moving green region. multiple agents with a shared experience replay were trained to achieve fast learning.<br></p> 

  <br>
    </td>
  </tr>

</tbody>

<tbody><tr>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <td width="25%"><img width="400" height="200" src="DRL-gifs/Pendulum.gif">
    </td><td width="75%" valign="top">
      <p><a href="https://github.com/satyadwyoom/Deep-Reinforcement-Learning/tree/master/SAC-Pendulum" target="_blank"><heading>A Soft-Actor-Critic based Agent</heading></a><br>
      <p>The agent learns to generate momentum by making the Pendulum move to and fro, so when the required momentum is achieved it is able to cross the midline and balance itself to point upwards.<br></p> 

  <br>
    </td>
  </tr>

</tbody>


</body></html>
